\section{State of the art}
Starting from the seminal work of Hodgins et al. \cite{}, controlling a physically simulated human character has been extensively studied in computer animation. A wide variety of human activities, including walking \cite{}, running \cite{}, swimming \cite{yang2004layered,kwatra2009fluid,Si:2014}, biking \cite{Hodgins:1995:AHA}, gymnastic motions \cite{}, reacting to perturbations \cite, getting up from falling \cite{} and manipulating objects with hands \cite{} are realistically synthesized in physically simulated environments. 

Two main categories of methods to synthesize human motions are trajectory optimization and reinforcement learning. Trajectory optimization optimizes a motion trajectory by minimizing a task-related objective subject to physical constraints. It has been applied to control the iconic jumping Luxo Jr lamp \cite{Witkin:1988}, humanoid characters \cite{Liu:2002,Jain:2009,Ye:2010}, and characters with arbitrary morphologies \cite{Wampler:2009}. The resulting motions are physically plausible and follow the animation principles such as anticipation and follow-through \cite{thomas:1995}.  Reinforcement learning algorithms solve a Markov Decision Process (MDP) to find optimal actions at different states. If the transition model is known, (fitted) value iteration has been successfully applied to generalize motion capture data \cite{Treuille:2007:NCA,Levine:2012:CCC}, to carry out locomotion tasks \cite{Coros:2009:RTC}, and to manipulate objects with hands \cite{Multifinger2013}. Policy search \cite{Ng:2000:PPS} is another reinforcement learning algorithm that can directly searches for a control policy without the need to construct a value function. Many studies on locomotion control \cite{Yin08,Wang:2009,Coros:2011,Wang:2012,Geijtenbeek:2013} performed policy search on parameterized controllers. 

Although we have seen impressive advances for last two decades, the gracefulness, agility and versatility of real human motions remain unmatched. There are challenges in physically-based character animation that need further investigation. First, controlling balance is a key problem to synthesize human motions in a physically-simulated environment. Balance can be maintained by exerting virtual forces \cite{Pratt2001,Coros2010}, applying linear feedback \cite{Laszlo:1996,Yin:2007,daSilva:2008,Coros2010}, using nonlinear control policies \cite{Muico:2009}, planning the contact forces \cite{Muico:2009,Tan:2012}, employing reduced models \cite{Tsai:2010,Kwon:2010,Mordatch:2010:RPL,Coros2010,Ye:2010} and training in stochastic environments \cite{Wang:2010}. Although the balance problem in simple locomotion tasks, such as walking and running, has been solved, maintaining balance in tasks that require agile motions remains an open problem. 

Another challenge is to effectively plan the contacts. Humans move themselves and other objects through contacts. However, contact events (contact breakage, sliding, etc.) can introduce discontinuous forces to the dynamics equation, which breaks the control space into fragmented feasible regions. As a result, a small change in control parameters can easily generate bifurcated consequences. For this reason, many previous methods
explicitly assumed that the contacts remain static
\cite{Abe:2007,Jain:2009,Kim:2011:DCO} while optimizing control forces
subject to equations of motion. This assumption significantly
restricts the effectiveness of the controller for locomotion and balance
because the controller is not allowed to actively exploit contact
breakage, slipping contacts, or rolling contacts to achieve control
goals. Three promising research directions to tackle this challenge are contact-invariant optimization \cite{Mordatch:2012,Mordatch:2013}, solving QPCC \cite{} and policy search with stochastic optimization \cite{Wu:2010:TAB,Wang:2010,Mordatch:2010:RPL}.

An important criteria in physically-based character animation is the realism of the synthesized motions. Even today, the quality of motions synthesized in physically-based character animation is still far from natural. This has prevent it from be used for many applications. One possible cause of the unnatural motion is the vast simplification by representing the human character as an articulated rigid body system. To improve the realism, prior work has simulated the dynamics of muscles and demonstrated complex interplay among bones, muscles, ligaments and other soft tissues can be modeled for individual body parts, including
the neck \cite{Lee:2006}, the upper body \cite{Zordan:2006,Dilorenzo:2008,Lee:2009:CBM}, lower body \cite{}, and hands
\cite{Tsang:2005,Sueda:2008}. However, constructing such a sophisticated biological model for a full human character is still computational prohibitive. An alternative solution is to augment a physically controlled character with realstic motion capture streams \cite{}. 














